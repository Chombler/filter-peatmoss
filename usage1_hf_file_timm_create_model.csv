github_url,file_path,signature,static_match
github.com/parkchamchi/DepthViewer,DEPTH/depthpy/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/lmb-freiburg/cv-exercises,solution07/code/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/SHI-Labs/Convolutional-MLPs,src/visualization/visualize.py,timm.models.create_model;timm.models.create_model,timm/mixer_b16_224.goog_in21k_ft_in1k
github.com/JXH-2020/yolov5_deepsort_age_gender_counting,Models.py,timm.create_model,timm/resnet50.a1_in1k
github.com/GitGyun/visual_token_matching,model/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/hmorimitsu/ptlflow,ptlflow/models/flowformer/encoders.py,timm.create_model;timm.create_model,timm/twins_svt_large.in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/IIGROUP/MANIQA,models/maniqa.py,timm.create_model,timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/Adapter-Hub/adapter-transformers,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/yuniw18/Joint_360depth,inference/DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/rodrigobaron/quick-deploy,examples/torch_timm/timm_resnet18_download.py,timm.create_model,timm/resnet18.a1_in1k
github.com/srvCodes/continual_learning_with_vit,src/test.py,timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/padeler/PE-former,models/transformer_vit.py,timm.models.create_model;timm.models.create_model,timm/resnet50.a1_in1k
github.com/Luckydog-lhy/Tensorrt_Mask2Former,Torch-TensorRT-universe/tests/modules/hub.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task3_efficientnet_b2/fold3.py,timm.create_model;timm.create_model,timm/efficientnet_b2.ra_in1k;timm/efficientnet_b2.ra_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/AutoVision-cloud/SSL-ViT-lowlabel-highdata,ssl-vit-retrieval/architectures/vits.py,timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/ML4SCI/DeepLense,Updating_the_DeepLense_Pipeline__Saranga_K_Mahanta/Classification/Model_II/model.py,timm.create_model,timm/efficientnet_b1.ft_in1k
github.com/MIDS-scaling-up/v2,week06/demo.py,timm.create_model,timm/mixnet_l.ft_in1k
github.com/isaaccorley/resize-is-all-you-need,src/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k
github.com/ActiveVisionLab/nope-nerf,DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zyddnys/sd_animation_optical_flow,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/LucaCorvitto/RealFaces_w_StableDiffusion,binary_classifiers.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/mobilenetv2_100.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/elicassion/3DTRL,model/vit.py,timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/abhishekkrthakur/tez,examples/image/flower_inference.py,timm.create_model,timm/resnet18.a1_in1k
github.com/rossjillian/cog-controlnet-11,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/thu-ml/ares,pytorch_ares/test/test_fgsm.py,timm.create_model,timm/resnet50.a1_in1k
github.com/Adonis-galaxy/DepthCLIP,DepthCLIP_code/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/mamonraab/Data-efficient-video-transformer,menovideo/menovideo.py,timm.create_model,timm/vgg19_bn.tv_in1k
github.com/asromahin/fline,examples/kaggle/gwd_box_verify.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/IIT-PAVIS/Positional_Diffusion,puzzle_diff/model/backbones/efficient_gat_new.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/rlawjdghek/A-fall-detection-model-in-diverse-conditions,main.py,timm.create_model,timm/rexnet_200.nav_in1k
github.com/164140757/SCM,lib/models/deit.py,timm.models.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/hwk0702/keras2torch,Adversarial_Attack/Projected_Gradient_Descent/main.py,timm.create_model,timm/resnet50.a1_in1k
github.com/dwardzheng/MFFN_COD,methods/classic_methods/HDFNet.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k
github.com/saba99/SuperResolution_Animation_Video,scripts/metrics/MANIQA/models/model_attentionIQA2.py,timm.create_model,timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/biasvariancelabs/aitlas,aitlas/models/vision_transformer.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/somepago/dbViz,models/ViT_pt_interpolate.py,timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/sgvaze/osr_closed_set_all_you_need,models/model_utils.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/LucaCorvitto/RealFaces_w_StableDiffusion,5_classes_classifiers.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/mobilenetv2_100.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_inceptionv4.py,timm.create_model,timm/inception_v4.tf_in1k
github.com/aartykov/Latent-Composer-pytorch,annotators/midas/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/Equationliu/GA-Attack,utils/architectures.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/inception_resnet_v2.tf_in1k;timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/tlpss/keypoint-detection,keypoint_detection/models/backbones/mobilenetv3.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,rijks_torch/learning_problems/efficientnetv2.py,timm.create_model;timm.create_model,timm/efficientnetv2_rw_m.agc_in1k;timm/efficientnetv2_rw_t.ra2_in1k
github.com/satya15july/depth_estimation_stereo_images,networks/FastACVNet/models/Fast_ACV_plus.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/gaochen315/DynamicNeRF,utils/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/camenduru/Rerender-hf,ControlNet/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/boyzwj/zface,models/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/aggelos-michael-papadopoulos/MobileViT-implementation-and-training-in-Tensorlow-and-Pytorch,Train on Pytorch/torch_inference.py,timm.create_model,timm/mobilevit_xxs.cvnets_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/csp_resnext50-mish/pthtar2onx.py,timm.models.create_model,timm/cspresnext50.ra_in1k
github.com/hongsunjang/Pipe-BD,NAS/arch_search.py,timm.models.create_model,timm/mobilenetv2_100.ra_in1k
github.com/wehrwein-research/border-legibility,MODEL/GMM/deep.py,timm.create_model,timm/resnext101_32x8d.tv_in1k
github.com/YanNeu/spurious_imagenet,utils/models/model_factory_224.py,timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model,timm/resnet50.a1_in1k;timm/tresnet_m.miil_in21k_ft_in1k;timm/seresnext26t_32x4d.bt_in1k;timm/seresnext50_32x4d.racm_in1k
github.com/nianticlabs/implicit-depth,modules/networks.py,timm.create_model,timm/mnasnet_100.rmsp_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_vit_modified.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/HolyWu/vs-midas,vsmidas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/rmcong/Hybrid-Label-SOD_TCSVT2022,net.py,timm.create_model,timm/resnet50.a1_in1k
github.com/PeterouZh/CIPS-3Dplusplus,exp/cips3d/models/vgg_per_loss.py,timm.create_model;timm.create_model;timm.create_model,timm/vgg16.tv_in1k
github.com/IIT-PAVIS/Positional_Diffusion,puzzle_diff/model/backbones/darknet_TransfConv.py,timm.create_model,timm/cspdarknet53.ra_in1k
github.com/layer6ai-labs/dgm-eval,dgm_eval/models/inception.py,timm.create_model,timm/inception_v3.tv_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/boostcampaitech2/image-classification-level1-23,model/model.py,timm.create_model;timm.create_model,timm/tf_efficientnet_b4.ns_jft_in1k
github.com/gangweiX/CGI-Stereo,models/CGI_Stereo.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yu-takagi/StableDiffusionReconstruction,codes/diffusion_sd2/stablediffusion/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ThereforeGames/txt2mask,repositories/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Chris-hughes10/pytorch-accelerated,examples/vision/using_timm_components/train_mixup_ema.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/tue-mps/cts-segmenter,policynet/policynet/net.py,timm.create_model,timm/efficientnet_lite0.ra_in1k
github.com/quatpv/GNN,models.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/zcxey2911/ControlNet_py3.10_cpu_NoConda,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Theia-4869/BiCross,DPT/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/kyegomez/Finetuning-Suite,Imagebind/BindDiffusion/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/dreamflake/ODI,utils.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/inception_resnet_v2.tf_in1k;timm/inception_v3.tv_in1k;timm/inception_v4.tf_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/built-in/diffusion/stablediffusion-2.1/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/GiangHLe/gans-evals,src/gans_eval/extractor.py,timm.create_model,timm/vgg16.tv_in1k
github.com/MAC-AutoML/PCL_AutoML_System,algorithm/classification/pytorch_automodel/image_classification/Compute_Flops.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/regnetx_032.tv2_in1k;timm/skresnext50_32x4d.ra_in1k;timm/mobilenetv2_120d.ra_in1k;timm/resnet26.bt_in1k;timm/mobilenetv2_100.ra_in1k
github.com/RobustBench/robustbench,robustbench/model_zoo/architectures/convstem_models.py,timm.models.create_model,timm/deit_small_patch16_224.fb_in1k
github.com/hwk0702/keras2torch,Computer_Vision/Finetuning_ViT_with_LoRA/main.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/iart-ai/prompt2prompt,stablediffusion/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/amiradridi/Job-Resume-Matching,venv/Lib/site-packages/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/boostcampaitech2/semantic-segmentation-level2-cv-13,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/compphoto/IntrinsicFlashPhotography,models/altered_midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_rn101.py,timm.create_model,timm/resnet101.a1h_in1k
github.com/rossjillian/cog-controlnet-11,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Jun-Pu/PAV-SOD,src/models/VIT.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/biasvariancelabs/aitlas,aitlas/models/hrnet.py,timm.create_model,timm/hrnet_w48.ms_in1k
github.com/Chris-hughes10/pytorch-accelerated,examples/vision/transfer_learning/pets_finetune.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/chaofengc/IQA-PyTorch,pyiqa/archs/ahiq_arch.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/Liuxinyv/SAZS,model/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/h2oai/wave-image-styling-playground,img_styler/image_prompt/control_net/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Georgefwt/Face-Landmark-ControlNet,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/juansensio/blog,070_pytorch_distributed/ddp.py,timm.create_model,timm/tf_efficientnet_b5.ns_jft_in1k
github.com/flyingsheepbin/pet-biometrics,v2_stage1/model_v2.py,timm.create_model,timm/tf_efficientnetv2_l.in21k_ft_in1k
github.com/EPFL-VILAB/3DCommonCorruptions,models/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zhoudw-zdw/RevisitingCIL,utils/inc_net.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/4uiiurz1/kaggle-pku-autonomous-driving,lib/models/resnet_fpn.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnext50_32x4d.a1h_in1k;timm/resnext50d_32x4d.bt_in1k
github.com/JunHeum/BiFormer,model/twins_encoder.py,timm.create_model;timm.create_model,timm/twins_svt_large.in1k;timm/twins_svt_small.in1k
github.com/yuniw18/Joint_360depth,DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Sierkinhane/VisorGPT,demo/ControlNet/controlnet/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/taimurhassan/rag-net-v2,Divs/VIT_AFFINITY_YTRUE.py,timm.create_model;timm.create_model,timm/vit_small_patch16_384.augreg_in21k_ft_in1k;timm/vit_small_patch32_384.augreg_in21k_ft_in1k
github.com/VQAssessment/BVQI,pyiqa/archs/ahiq_arch.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/VideoCrafter/VideoCrafter,extralibs/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task3_efficientnet_b2/fold4.py,timm.create_model;timm.create_model,timm/efficientnet_b2.ra_in1k;timm/efficientnet_b2.ra_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/Pseudo_label_learning/Task2/Task2_vgg19.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/nianticlabs/implicit-depth,experiment_modules/bd_model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnext101_64x4d.c1_in1k;timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288;timm/resnet18d.ra2_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sagizty/MIL-SI,MIL/MIL_model.py,timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model.state_dict;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v11/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/Ascend/ModelZoo-PyTorch,ACL_PyTorch/built-in/cv/EfficientNetV2_for_Pytorch/preprocess.py,timm.create_model,timm/efficientnetv2_rw_t.ra2_in1k
github.com/tsujuifu/pytorch_empirical-mvm,visbackbone/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task2_vgg19/fold0.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/somepago/dbViz,model.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/facebookresearch/DistDepth,dpt_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/christianbrendel/diffusion-model-learnings,stablediffusion-repo/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ashawkey/stable-dreamfusion,dpt.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/amro-kamal/ObjectPose,src/Models/Models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/convnext_large.fb_in22k_ft_in1k;timm/convit_base.fb_in1k;timm/convit_small.fb_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k;timm/swin_large_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k;timm/deit_small_distilled_patch16_224.fb_in1k
github.com/ML4SCI/DeepLense,DeepLense_Classification_Transformers_Archil_Srivastava/models/transformers/hybrid_swin.py,timm.create_model,timm/efficientnet_b3.ra2_in1k
github.com/mshukor/VLPCook,recipe1m/models/networks/image_networks/networks.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/27182812/ChatGLM-LLaMA-chinese-insturct,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,rijks_torch/learning_problems/swin.py,timm.create_model;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/ChaosCodes/ProPETL,propetl-roberta/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/NHERI-SimCenter/BRAILS,brails/legacy/modules/PytorchGenericModelClassifier/GenericImageClassifier.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/deforum-art/deforum-stable-diffusion,src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sjg02122/MonoFormer,monoformer/utils/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zju3dv/deltar,src/models/encoder.py,timm.create_model,timm/tf_efficientnetv2_b3.in21k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v1/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/MikeGu721/EasyLLM,installs/transformers-install/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/layumi/U_turn,model.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,ACL_PyTorch/built-in/cv/EfficientNetV2_for_Pytorch/pth2onnx.py,timm.create_model,timm/efficientnetv2_rw_t.ra2_in1k
github.com/pierrefdz/stable_signature,src/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/facebookresearch/grounding-inductive-biases,equivariance_measure/embedding_distances.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/openvinotoolkit/nncf,tests/torch/experimental/replace_custom_modules/test_replace_timm_custom_modules.py,timm.create_model,timm/mobilenetv3_small_050.lamb_in1k
github.com/boostcampaitech5/level1_imageclassification-cv-14,main/model.py,timm.create_model;timm.create_model,timm/efficientnet_b4.ra2_in1k;timm/efficientnet_b4.ra2_in1k
github.com/nku-shengzheliu/PaddlePaddle-Swin-Transformer-V2,port_weights/load_pytorch_weights_384.py,timm.create_model,timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task3_efficientnet_b2/fold0.py,timm.create_model;timm.create_model,timm/efficientnet_b2.ra_in1k;timm/efficientnet_b2.ra_in1k
github.com/aniketmaurya/stable_diffusion_inference,src/ldm2/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zhenxingjian/Partial_Distance_Correlation,Partial_Distance_Correlation/VGG.py,timm.create_model,timm/vgg19_bn.tv_in1k
github.com/juansensio/blog,072_pytorch_docker/script/main.py,timm.create_model,timm/tf_efficientnet_b5.ns_jft_in1k
github.com/sjg02122/MonoFormer,monoformer/networks/depth/blocks.py,timm.create_model,timm/twins_svt_base.in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/lartpang/MethodsCmp,methods/cvpr2022_zoomnet/zoomnet.py,timm.create_model,timm/resnet50.a1_in1k
github.com/lennart-maack/domain_adaptation,other_SOTAs/CoFo/models/backbone.py,timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/tf_efficientnet_b7.ns_jft_in1k
github.com/mbaradad/depth_prompt,baselines/omnidata_main/omnidata_tools/torch/modules/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/runpod/serverless-workers,workers/ControlNet/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/lllyasviel/ControlNet,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v11/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/parkchamchi/DepthViewer,DEPTH/depthpy/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/statusrank/XCurve,XCurve/OpenAUC/utils/model_utils.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/yhlleo/MJP,gradvit/gradvit_eval_grad-abit.py,timm.create_model;timm.create_model.cuda,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/HolyWu/vs-midas,vsmidas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/QingruZhang/AdaLoRA,NLG_QA/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/drivendataorg/hakuna-madata,2nd Place/thunder-hammer/thunder_hammer/model/classification/timm_ft.py,timm.create_model;timm.create_model,timm/nasnetalarge.tf_in1k
github.com/sagizty/MIL-SI,Models/getmodel.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_384.augreg_in21k_ft_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_tiny_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vgg16_bn.tv_in1k;timm/vgg16.tv_in1k;timm/vgg19_bn.tv_in1k;timm/vgg19.tv_in1k;timm/deit_base_patch16_384.fb_in1k;timm/deit_base_patch16_224.fb_in1k;timm/twins_pcpvt_base.in1k;timm/pit_b_224.in1k;timm/convit_base.fb_in1k;timm/botnet26t_256.c1_in1k;timm/densenet121.ra_in1k;timm/visformer_small.in1k;timm/coat_mini.in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/inception_v3.tv_in1k;timm/coat_lite_small.in1k
github.com/boostcampaitech2/image-classification-level1-08,solution/cnn_engine/model/model.py,timm.create_model;timm.create_model,timm/eca_nfnet_l2.ra3_in1k
github.com/xiaoxiaokuaile/2022DCIC_OCR,Tool_code/Img_aug/timm.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet34.a1_in1k;timm/resnest101e.in1k;timm/resnet34.a1_in1k;timm/resnet18.a1_in1k;timm/resnet50.a1_in1k
github.com/lartpang/ZoomNet,methods/classic_methods/HDFNet.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,ACL_PyTorch/contrib/cv/classfication/pnasnet5large/pnasnet5large_onnx.py,timm.create_model,timm/pnasnet5large.tf_in1k
github.com/pytorch/TensorRT,tools/perf/hub.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/DannielSilva/MM-VQA,vqamed2019/grad_cam.py,timm.create_model,timm/tf_efficientnetv2_m.in21k_ft_in1k
github.com/kspruthviraj/Plankiformer,utils/for_cifar10.py,timm.create_model;timm.create_model,timm/tf_efficientnet_b7.ns_jft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k
github.com/alexhock/pixplotml,prep_pixplot_files/main.py,timm.create_model;timm.create_model,timm/resnetrs50.tf_in1k;timm/resnetrs50.tf_in1k
github.com/gangweiX/IGEV,IGEV-MVS/core/extractor.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/aliasgharkhani/Masktune,src/models/resnet50.py,timm.create_model,timm/resnet50.a1_in1k
github.com/BrainCog-X/Brain-Cog,examples/Perception_and_Learning/img_cls/bp/main.py,timm.models.create_model;timm.models.create_model,timm/resnet50d.ra2_in1k
github.com/PerceptionComputingLab/ULTRA,SLDL/net.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k
github.com/yhlleo/MJP,gradvit/gradVit.py,timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/czhao39/neurips-attention,baseline_cnns/get_passive_attention_unlabeled_imagenet.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/hbin0701/VT_with_NR_for_FER,models/SwinT.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/Teragion/Sea-Thru-Impl,midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/facebookresearch/clip-rocket,models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/convnext_tiny.in12k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch32_224.augreg_in21k_ft_in1k;timm/resnet50.a1_in1k;timm/resnet50.a1_in1k;timm/convnext_small.in12k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch32_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/JamesQFreeman/LoRA-ViT,adapter.py,timm.create_model,timm/vit_base_patch16_224.orig_in21k_ft_in1k
github.com/UIUC-ChenLab/YouHome-Dataset,Examples/model.py,timm.create_model;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/convnext_base.fb_in22k_ft_in1k;timm/hrnet_w18.ms_aug_in1k
github.com/pytorch/TensorRT,tests/modules/hub.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/thu-ml/ares,pytorch_ares/test/test_autoattack.py,timm.create_model,timm/resnet50.a1_in1k
github.com/610265158/face_landmark_pytorch,lib/core/model/face_model.py,timm.create_model,timm/tf_mobilenetv3_large_minimal_100.in1k
github.com/sagizty/Insight,colab_sample/MAE_main.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/M4xim4l/InNOutRobustness,utils/models/model_factory_224.py,timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model,timm/resnet50.a1_in1k;timm/tresnet_m.miil_in21k_ft_in1k;timm/seresnext26t_32x4d.bt_in1k;timm/seresnext50_32x4d.racm_in1k
github.com/eslambakr/LAR-Look-Around-and-Refer,referit3d/models/default_blocks.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/convnext_tiny.in12k_ft_in1k;timm/convnext_tiny.in12k_ft_in1k;timm/convnext_tiny.in12k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task2_vgg19/fold4.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/cyZhu98/Identification-of-crop-growth,main.py,timm.create_model;timm.create_model,timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k
github.com/drinkingcoder/NeuralMarker,core/encoders.py,timm.create_model;timm.create_model,timm/twins_svt_large.in1k
github.com/carefree0910/carefree-learn,cflearn/api/cv/third_party/midas/core/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/lmb-freiburg/cv-exercises,ex07/code/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/nku-shengzheliu/PaddlePaddle-Swin-Transformer-V2,port_weights/load_pytorch_weights.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/Sygil-Dev/Sygil-WebUI,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/longbai1006/Surgical-VQLA,models/LViTPrediction.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/elicassion/3DTRL,model/transformer_projector.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/csp_resnext50-mish/demo.py,timm.models.create_model,timm/cspresnext50.ra_in1k
github.com/ZrrSkywalker/Point-Bind,models/PointBind_models.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_mlp_mixer.py,timm.create_model,timm/mixer_b16_224.goog_in21k_ft_in1k
github.com/ML4SCI/DeepLense,Updating_the_DeepLense_Pipeline__Saranga_K_Mahanta/Classification/Model_I/model.py,timm.create_model,timm/efficientnet_b2.ra_in1k
github.com/nmndeep/revisiting-at,utils_architecture.py,timm.models.create_model;timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/deit_small_patch16_224.fb_in1k;timm/inception_v3.tv_in1k
github.com/zcxey2911/ControlNet_py3.10_cpu_NoConda,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zhenxingjian/Partial_Distance_Correlation,Partial_Distance_Correlation/ViT_model_train.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/resnet18.a1_in1k
github.com/autonomousvision/projected-gan,pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/TianheWu/Assessor360,models/assessor360.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/zixuzhuang/CSNet,comparesions/DC_MT/dcmt.py,timm.create_model,timm/resnet18.a1_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ffs333/2nd_place_GISLR,GISLR_utils/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/tf_efficientnet_b0.ns_jft_in1k;timm/tf_efficientnetv2_b1.in1k
github.com/seculayer/AutoAPE-challenge4,dacon/컴퓨터비전 이상치 탐지 알고리즘 경진대회/codes/model/model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b3.ra2_in1k;timm/wide_resnet50_2.racm_in1k;timm/wide_resnet101_2.tv_in1k;timm/cait_s36_384.fb_dist_in1k;timm/tf_efficientnet_b6.ns_jft_in1k
github.com/wxj630/visual-chatgpt-zh,modules/controlnet_aux/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/kzl/universal-computation,universal_computation/fpt.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/eps696/SDfu,src/xtra/clipseg/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Reza-Zhu/SUES-200-Benchmark,loss_func/loss_model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k;timm/seresnet50.a1_in1k;timm/seresnet50.a1_in1k;timm/resnest50d.in1k;timm/resnest50d.in1k;timm/vgg16_bn.tv_in1k;timm/vgg16_bn.tv_in1k;timm/densenet201.tv_in1k;timm/densenet201.tv_in1k;timm/efficientnet_b4.ra2_in1k;timm/efficientnet_b4.ra2_in1k;timm/inception_v4.tf_in1k;timm/inception_v4.tf_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/dwardzheng/MFFN_COD,methods/classic_methods/MINet.py,timm.create_model;timm.create_model,timm/vgg16_bn.tv_in1k;timm/resnet50.a1_in1k
github.com/aartykov/Latent-Composer-pytorch,annotators/midas/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/boostcampaitech4lv23cv2/final-project-level3-cv-13,ml/feature_map/Fish/visualizing.py,timm.create_model,timm/efficientnet_b4.ra2_in1k
github.com/compphoto/RealisticImageEnhancement,model/MiDaS/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/nianticlabs/implicit-depth,experiment_modules/depth_model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnext101_64x4d.c1_in1k;timm/seresnextaa101d_32x8d.sw_in12k_ft_in1k_288;timm/resnet18d.ra2_in1k
github.com/JeiKeiLim/kindle,kindle/generator/pretrained.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task3_efficientnet_b2/fold1.py,timm.create_model;timm.create_model,timm/efficientnet_b2.ra_in1k;timm/efficientnet_b2.ra_in1k
github.com/ml-jku/cloome,src/clip/model.py,timm.create_model,timm/resnet50.a1_in1k
github.com/bryant1410/fitclip,aligner/encoder/slip.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/boostcampaitech2/final-project-level3-cv-04,model_lab/frame_classification/custom/golden/recipe.py,timm.create_model,timm/efficientnet_b5.sw_in12k_ft_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/swin.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/bigcode-project/transformers,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/JayQine/MGD-SSSS,furnace/base_model/resnet.py,timm.create_model,timm/resnet18d.ra2_in1k
github.com/smly/kaggle-book-gokui,chapter3/train.py,timm.create_model,timm/regnety_080.ra3_in1k
github.com/fupiao1998/TransformerSOD,model/backbone/DPT_blocks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/drivendataorg/zamba,zamba/models/efficientnet_models.py,timm.create_model,timm/efficientnetv2_rw_m.agc_in1k
github.com/razeghi71/stable-diffusion-v2-m1,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/vit_double.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/chunhuizhang/bilibili_vlogs,pretrained/swin/demo.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/drivendataorg/cloud-cover-winners,1st place/src/unet_efficient_netV2_b2_train_fp16_custom_aug.py,timm.create_model,timm/tf_efficientnetv2_b2.in1k
github.com/610265158/Peppa_Pig_Face_Landmark,TRAIN/face_landmark/lib/core/base_trainer/model.py,timm.create_model;timm.create_model,timm/mobilenetv3_large_100.ra_in1k;timm/hrnet_w18.ms_aug_in1k
github.com/mr-eggplant/SAR,main.py,timm.create_model;timm.create_model,timm/resnet50_gn.a1h_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/ML4SCI/DeepLense,Updating_the_DeepLense_Pipeline__Saranga_K_Mahanta/Classification/Model_III/model.py,timm.create_model,timm/efficientnet_b1.ft_in1k
github.com/guanyuezhen/AR-CDNet,models/encoder.py,timm.create_model,timm/resnet18d.ra2_in1k
github.com/iliasprc/COVIDNet,tests/test_models.py,timm.create_model,timm/efficientnet_b1.ft_in1k
github.com/HolyWu/vs-midas,vsmidas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/eps696/SD,src/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sail-sg/BindDiffusion,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/lllyasviel/ControlNet,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/jacobgil/pytorch-grad-cam,usage_examples/swinT_example.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/aws-samples/deploy-stable-diffusion-model-on-amazon-sagemaker-endpoint,ControlNet_SageMaker_Hosting/ControlNet_bring_your_own_container/container/ControlNet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/google-research/3d-moments,third_party/DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/tokudayo/NekoNet,models/descriptors.py,timm.create_model;timm.create_model;timm.create_model,timm/tf_efficientnetv2_b0.in1k;timm/tf_efficientnetv2_s.in21k_ft_in1k;timm/mobilenetv3_large_100.ra_in1k
github.com/AIGText/GlyphControl-release,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sangwook236/SWDT,sw_dev/python/rnd/test/machine_learning/timm_test.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model.eval;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/mobilenetv3_large_100.ra_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/xception41.tf_in1k;timm/resnet50.a1_in1k;timm/densenet121.ra_in1k;timm/resnet50.a1_in1k;timm/ese_vovnet19b_dw.ra_in1k;timm/resnest26d.gluon_in1k;timm/regnety_032.ra_in1k;timm/ecaresnet101d.miil_in1k;timm/resnet18.a1_in1k
github.com/dwardzheng/MFFN_COD,methods/MFFN/MFFN.py,timm.create_model,timm/resnet50.a1_in1k
github.com/jmerullo/limber,image_encoders.py,timm.create_model,timm/nf_resnet50.ra2_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Liuxinyv/SAZS,model/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/timojl/clipseg,models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v11/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/robintzeng/mask-rcnn-Pytorch,model/modified_mask_rcnn.py,timm.create_model,timm/cspresnet50.ra_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/tkm2261/kaggle_petfinder,protos/breed.py,timm.create_model,timm/efficientnet_b1.ft_in1k
github.com/ziplab/SN-Net,stitching_resnet_swin/train.py,timm.models.create_model;timm.models.create_model,timm/regnety_160.sw_in12k_ft_in1k
github.com/dwojtasik/PyHook,PyHook/pipelines/ai_depth_estimation.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/beroguedou/basmatinet,basmatinet/ml/models.py,timm.create_model,timm/efficientnet_b4.ra2_in1k
github.com/dreamflake/CFM,utils.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/inception_resnet_v2.tf_in1k;timm/inception_v3.tv_in1k;timm/inception_v4.tf_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/levit_384.fb_dist_in1k;timm/convit_base.fb_in1k;timm/twins_svt_base.in1k;timm/pit_s_224.in1k
github.com/TencentARC/T2I-Adapter,ldm/modules/extra_condition/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/satya15july/depth_estimation_stereo_images,networks/FastACVNet/models/Fast_ACV.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/vlmaps/vlmaps,lseg/modules/models/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/XmYx/ainodes-pyside,ldm_v2/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/flyingsheepbin/pet-biometrics,v2_stage1/model_v2_infer.py,timm.create_model,timm/tf_efficientnetv2_l.in21k_ft_in1k
github.com/prabhuomkar/bitbeast,torchlego/docs/models/classification.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/Equationliu/GA-Attack,Competition/code/utils.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_base_distilled_patch16_384.fb_in1k;timm/dm_nfnet_f1.dm_in1k;timm/ecaresnet269d.ra2_in1k;timm/inception_v4.tf_in1k;timm/inception_resnet_v2.tf_in1k;timm/cspdarknet53.ra_in1k;timm/densenet201.tv_in1k;timm/repvgg_b2g4.rvgg_in1k;timm/dpn107.mx_in1k
github.com/mshukor/eP-ALM,models/ast.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_base_distilled_patch16_384.fb_in1k
github.com/MadryLab/failure-directions,failure_directions/src/model_utils.py,timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/tue-mps/cts-segmenter,segm/model/policy_net.py,timm.create_model,timm/efficientnet_lite0.ra_in1k
github.com/chaofengc/IQA-PyTorch,pyiqa/archs/maniqa_arch.py,timm.create_model,timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/dedoogong/ThunderNet-pytorch,tmp.py,timm.create_model,timm/resnet26d.bt_in1k
github.com/Ascend/ModelZoo-PyTorch,ACL_PyTorch/contrib/cv/classfication/TResNet/TResNet_pth2onnx.py,timm.create_model,timm/tresnet_m.miil_in21k_ft_in1k
github.com/iliasprc/SSL-vit-cnn,model/cnn.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b1.ft_in1k;timm/efficientnet_b1.ft_in1k;timm/efficientnet_b0.ra_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/pit_ti_224.in1k;timm/efficientnet_b0.ra_in1k;timm/efficientnet_b1.ft_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/tanveer-hussain/EfficientSOD2,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/isl-org/MiDaS,midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/HolyWu/vs-midas,vsmidas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/cambridgeltl/autopeft,adapter-transformers-adapters3.1.0/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/610265158/mobile_centernet,lib/core/model/centernet.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/HelixNGC7293/DeforumStableDiffusionLocal,deforum-stable-diffusion/src/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Baiyuetribe/ncnn-models,image_classification/cait/models/convert.py,timm.create_model,timm/cait_xxs36_384.fb_dist_in1k
github.com/Rajhans0/Poly_INR,feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Test/query/models_isc/hrnet.py,timm.create_model,timm/hrnet_w30.ms_in1k
github.com/MartinFabianIonut/University,Year 2/Semester 4/Artificial Intelligence/Laboratory 11/Emotion/main_multilabel.py,timm.create_model,timm/resnetv2_50.a1h_in1k
github.com/inspire-group/PatchCleanser,train_model.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_swinTransformer.py,timm.create_model,timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/nayeon7lee/factuality_enhanced_lm_hf,transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/arenasys/sd-inference-server,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/shenxiaowrj/tfsss,deep_thoughts/fruit_classification_based_maecode/train实用版.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet18.a1_in1k
github.com/louis-she/rsna-2022-public,models.py,timm.create_model;timm.create_model;timm.create_model,timm/convnextv2_nano.fcmae_ft_in22k_in1k
github.com/ChenWu98/unified-generative-zoo,model/lib/stylegan_xl/feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/PKU-ML/ContraNorm,BERT_gleu/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/deeptibhegde/CLIP-goes-3D,models/SLIP/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/microsoft/torchgeo,torchgeo/models/vit.py,timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/ShihaoZhaoZSH/Uni-ControlNet,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/thu-ml/ares,pytorch_ares/test/test_deepfool.py,timm.create_model,timm/resnet50.a1_in1k
github.com/parkchamchi/DepthViewer,DEPTH/depthpy/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/kspruthviraj/Plankiformer,utils/model_training.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_base_distilled_patch16_224.fb_in1k;timm/tf_efficientnet_b7.ns_jft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k;timm/tf_efficientnet_b7.ns_jft_in1k
github.com/facebookresearch/grounding-inductive-biases,equivariance_measure/embedding_alignments.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/parkchamchi/DepthViewer,DEPTH/depthpy/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/anilkagak2/DiSK_Distilling_Scaffolded_Knowledge,models.py,timm.create_model,timm/tf_efficientnetv2_s.in21k_ft_in1k
github.com/nku-shengzheliu/PaddlePaddle-Swin-Transformer-V2,port_weights/load_pytorch_weights_large_384.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/tlpss/keypoint-detection,keypoint_detection/models/backbones/convnext_unet.py,timm.create_model,timm/convnext_femto.d1_in1k
github.com/whitesnowdrop/MuFAN,model/encoder.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/asanakoy/kaggle-lyft-motion-prediction-av,src/1st_level/models_common.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet34.a1_in1k;timm/resnet50.a1_in1k;timm/seresnext26t_32x4d.bt_in1k;timm/seresnext50_32x4d.racm_in1k;timm/efficientnet_b2.ra_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/hrnet_w18.ms_aug_in1k;timm/hrnet_w18_small.ms_in1k;timm/hrnet_w18_small_v2.ms_in1k;timm/xception41.tf_in1k;timm/xception65.ra3_in1k;timm/xception71.tf_in1k;timm/densenet121.ra_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/vit_base_patch32_224/vit_train.py,timm.models.create_model;timm.create_model,timm/vit_base_patch32_224.augreg_in21k_ft_in1k
github.com/ShuzhaoXie/Armol,src/armor_test.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/xinntao/HandyInfer,handyinfer/depth_estimation/DPT_BEiT_L_384_arch.py,timm.create_model,timm/beit_large_patch16_384.in22k_ft_in22k_in1k
github.com/bobo0810/Classification,Models/Backbone/backbone.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/efficientnet_b0.ra_in1k
github.com/hpcaitech/ColossalAI,examples/images/diffusion/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/wllmzhu/G-VUE,models/v_backbone.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/facebookresearch/diffq,examples/cifar/train.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/isl-org/MiDaS,midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/Hanson0910/Pytorch-RIADD,subnmit_riadd.py,timm.models.create_model;timm.models.create_model;timm.models.create_model;timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/resnet200d.ra2_in1k;timm/nf_resnet50.ra2_in1k
github.com/eps696/SD,src/xtra/clipseg/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/db0/nataili,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_beit.py,timm.create_model,timm/beit_base_patch16_224.in22k_ft_in22k_in1k
github.com/isl-org/lang-seg,modules/models/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/riccardomusmeci/saldet,saldet/models/models/pgnet.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/hhsinping/few_shot_fas,fas.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/TencentARC/AnimeSR,scripts/metrics/MANIQA/models/model_attentionIQA2.py,timm.create_model,timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/jlianglab/BenchmarkTransformers,models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/deit_base_patch16_224.fb_in1k;timm/beit_base_patch16_224.in22k_ft_in22k_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/deit_small_patch16_224.fb_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/WindVChen/DiffAttack,other_attacks.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_base_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/mixer_b16_224.goog_in21k_ft_in1k;timm/mixer_l16_224.goog_in21k_ft_in1k
github.com/YuiNsky/Gradient-based-depth-map-fusion,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ashawkey/nerf2mesh,depth_tools/dpt.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/camenduru/Rerender-hf,ControlNet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zetyquickly/DensePoseFnL,fpn.py,timm.create_model,timm/spnasnet_100.rmsp_in1k
github.com/obeychoi0120/YOLOv5-GradCAM,pytorch-grad-cam/usage_examples/swinT_example.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/KevinMusgrave/pytorch-adapt,src/pytorch_adapt/models/pretrained.py,timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/luogantt/onnxruntime_cpp_demo,onnx_python/torch_model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/cspdarknet53.ra_in1k;timm/senet154.gluon_in1k;timm/seresnet50.a1_in1k;timm/resnest50d.in1k
github.com/thygate/stable-diffusion-webui-depthmap-script,dmidas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/alibaba/EasyNLP,examples/diffusion_video_stylizer/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/NickKaparinos/Kaggle-PetFinder.my-Pawpularity-Contest,utilities.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/zachary-shah/riff-cnet,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/NoBlackBoxes/LastBlackBox,boxes/intelligence/transformers/vision/nose/model.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/distable/core,src_plugins/midas3d/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/isl-org/lang-seg,modules/models/lseg_vit_zs.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/FewshotML/plix,plixkws/backbone.py,timm.create_model;timm.create_model,timm/tinynet_e.in1k;timm/tf_efficientnetv2_m.in21k_ft_in1k
github.com/oke-aditya/quickvision,examples/classification/training_sota_cnns.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/SPNASNet_100_for_PyTorch/pthtar2onnx.py,timm.create_model,timm/spnasnet_100.rmsp_in1k
github.com/Baiyuetribe/ncnn-models,image_classification/res2net/models/convert.py,timm.create_model,timm/res2net101_26w_4s.in1k
github.com/chaoyi-wu/finetune_llama,Python_Package/transformers-main/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/shariqfarooq123/LocalBins,models/backbone/densenet.py,timm.create_model,timm/densenet161.tv_in1k
github.com/ThereforeGames/unprompted,lib_unprompted/stable_diffusion/controlnet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/aaronzguan/Motion-Prediction-for-Autonomous-Vehicle,networks.py,timm.create_model,timm/xception41.tf_in1k
github.com/faris-k/fastsiam-wafers,scripts/models/fastsiam.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/convnextv2_nano.fcmae_ft_in22k_in1k
github.com/huggingface/accelerate,examples/complete_cv_example.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/parkchamchi/DepthViewer,DEPTH/depthpy/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/boostcampaitech4cv3/level1_imageclassification_cv-level1-cv-20,baseline/baseline_jaeyoung_lightning/models.py,timm.create_model,timm/resnext50_32x4d.a1h_in1k
github.com/czhao39/neurips-attention,baseline_cnns/get_imagenet_confidences.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/kentaroy47/vision-transformers-cifar10,train_cifar10.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/xingyi-li/3d-cinemagraphy,third_party/DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/aliencaocao/TIL-2022,til-final-v2/stubs/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/wizard1203/VHL,model/utils/model_scan.py,timm.create_model;timm.create_model,timm/mobilenetv3_large_100.ra_in1k;timm/efficientnet_b0.ra_in1k
github.com/Anything-of-anything/Anything-3D,AnyObject3D/src/3DFuse/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/lartpang/ZoomNet,methods/zoomnet/zoomnet.py,timm.create_model,timm/resnet50.a1_in1k
github.com/junyangwang0410/Knight,transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/apple/ml-destseg,model/destseg.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k
github.com/IzumiSatoshi/deforumed-walk,src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/HighCWu/ControlLoRA,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/nannullna/snapshot-al,scripts/commons.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/flyingsheepbin/pet-biometrics,v2_stage2/model_v2_infer.py,timm.create_model,timm/tf_efficientnetv2_l.in21k_ft_in1k
github.com/diffus3/comfy_clipseg,models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/dogoulis/kg_visual_skin_cancer,cv/evaluation.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/gangweiX/Fast-ACVNet,models/Fast_ACV.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/chaofengc/IQA-PyTorch,pyiqa/archs/iqt_arch.py,timm.create_model,timm/inception_resnet_v2.tf_in1k
github.com/slimgroup/GCS-CAM,scripts/model.py,timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/zhenxingjian/Partial_Distance_Correlation,Partial_Distance_Correlation/resnet.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet34.a1_in1k;timm/resnet50.a1_in1k;timm/resnet152.a1h_in1k;timm/resnext50_32x4d.a1h_in1k
github.com/thu-coai/PICL,transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/eslambakr/HRS_benchmark,codes/t2i_models/sd_v2/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/mshukor/TFood,recipe1m/models/networks/image_networks/networks.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/aws-samples/deploy-stable-diffusion-model-on-amazon-sagemaker-endpoint,ControlNet_SageMaker_Hosting/ControlNet_bring_your_own_container/container/ControlNet/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/mbanani/lgssl,hubconf.py,timm.create_model,timm/resnet50.a1_in1k
github.com/amazon-science/peft-design-spaces,models/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/yhlleo/MJP,gradvit/gradvit_eval.py,timm.create_model;timm.create_model.cuda,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/XFeiF/SSAN-pytorch,ssan.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/cdluminate/robrank,robrank/models/template_rank.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/swin_tiny_patch4_window7_224.ms_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_large_patch4_window7_224.ms_in22k_ft_in1k
github.com/cedrickchee/transformers-llama,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/gangweiX/IGEV,IGEV-Stereo/core/extractor.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/Zongwei97/HIDANet,Code/lib/res2net_gba.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/res2net50_26w_4s.in1k;timm/res2net50_26w_4s.in1k;timm/res2net50_26w_4s.in1k;timm/res2net50_26w_4s.in1k
github.com/sjg02122/MonoFormer,monoformer/networks/depth/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/iliasprc/SSL-vit-cnn,selfsl/ssl_models/simsiam.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/efficientnet_b1.ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/pit_ti_224.in1k
github.com/haha-lisa/RDM-Region-Aware-Diffusion-Model,models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Ascend/samples,best_practices/contrib/RT-GazeEstimation/train/train.py,timm.create_model,timm/resnet18.a1_in1k
github.com/WangFeng18/Segment-Anything-in-NeRF,samnerf/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zjuerme/zju_course,人工智能安全/Lab/CIFAR10_transformerVision/model.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/JamesQFreeman/LoRA-ViT,lora.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/xudoong/EdgeVisionTransformer,tools.py,timm.create_model;timm.create_model,timm/mobilenetv2_100.ra_in1k;timm/mobilenetv3_large_100.ra_in1k
github.com/pytorch/TensorRT,tools/perf/utils.py,timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/neuralchen/SimSwap,pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/thu-ml/ares,pytorch_ares/test/test_cw.py,timm.create_model,timm/resnet50.a1_in1k
github.com/canktech/xview2unet,effdamageunet.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/ngthanhtin/VLSP_ImageCaptioning,models/model.py,timm.create_model;timm.create_model;timm.create_model,timm/efficientnetv2_rw_s.ra2_in1k;timm/efficientnetv2_rw_m.agc_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/dev/perf/Swin_Cifar10/train_cifar10.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/modelscope/modelscope,modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v11/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/zhengzangw/DoPrompt,domainbed/networks.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/IIT-PAVIS/Positional_Diffusion,puzzle_diff/model/backbones/efficient_gat.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/VQAssessment/BVQI,pyiqa/archs/maniqa_arch.py,timm.create_model,timm/vit_base_patch8_224.augreg2_in21k_ft_in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/isl-org/MiDaS,midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/microsoft/torchgeo,torchgeo/models/resnet.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet50.a1_in1k
github.com/XiangLi1999/ContrastiveDecoding,transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/asromahin/fline,examples/fakes/fake_gen_classifier.py,timm.create_model,timm/resnet18.a1_in1k
github.com/dixiyao/Patch-Shuffling-Transformer,BlackBoxAttacker/model.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/aartykov/Latent-Composer-pytorch,annotators/midas/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/thygate/stable-diffusion-webui-depthmap-script,dmidas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/lartpang/CAVER,method/caver.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50d.ra2_in1k;timm/resnet50d.ra2_in1k;timm/resnet101d.ra2_in1k;timm/resnet101d.ra2_in1k
github.com/Amsterdam/public-eye,eelib/networks/registry.py,timm.models.create_model,timm/deit_base_distilled_patch16_224.fb_in1k
github.com/p-ranav/PhotoLab,src/MiDaS.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/shihyung/image_classification_flower102,src/inference.py,timm.create_model,timm/tf_efficientnet_b0.ns_jft_in1k
github.com/ethz-spylab/diffusion_denoised_smoothing,imagenet/DRM.py,timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k
github.com/sail-sg/EditAnything,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/devsapp/fc-stable-diffusion-plus,src/code/sd-resource/extensions/sd-webui-deforum/scripts/deforum_helpers/src/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/isl-org/DPT,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/HashmatShadab/APR,classification.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/lartpang/ZoomNet,methods/classic_methods/MINet.py,timm.create_model;timm.create_model,timm/vgg16_bn.tv_in1k;timm/resnet50.a1_in1k
github.com/ZhangYuanhan-AI/Bamboo,Bamboo-Benchmark/models/timmvit.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/aurooj/WSG-VQA-VLTransformers,src/lxrt/modeling_capsbert.py,timm.create_model;timm.create_model,timm/vit_base_patch32_224.augreg_in21k_ft_in1k;timm/vit_base_patch32_224.augreg_in21k_ft_in1k
github.com/yhlleo/MJP,gradvit/gradvit_losses.py,timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/perpetio/magic_avatars,server/app/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/XuelianCheng/SLT-Net,lib/pvtv2_afterTEM.py,timm.models.create_model,timm/pvt_v2_b5.in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/demo.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/pthtar2onx.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/linghu8812/tensorrt_inference,project/Swin-Transformer/export_onnx.py,timm.create_model,timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/rezafuru/FrankenSplit,misc/loss.py,timm.create_model,timm/swin_s3_tiny_224.ms_in1k
github.com/aartykov/Latent-Composer-pytorch,annotators/midas/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/JunlinHan/MachineMem,GANalyze_instructions/mmnet.py,timm.models.create_model,timm/resnet50.a1_in1k
github.com/Baiyuetribe/ncnn-models,image_classification/efficientnet/models/convert.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/SusungHong/IF-DreamFusion,dpt.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yoctta/XPaste,segment_methods/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yujiariyasu/siim_covid19_detection,siim_yuji/models/model_4channels.py,timm.create_model;timm.create_model;timm.create_model,timm/resnet34.a1_in1k;timm/resnet18.a1_in1k
github.com/srvCodes/continual_learning_with_vit,src/networks/timm_vit_tiny_16_augreg_224.py,timm.create_model;timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/SHI-Labs/Prompt-Free-Diffusion,lib/model_zoo/controlnet_annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/rossjillian/cog-controlnet-11,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/facebookresearch/robust-dynrf,scripts/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/flowersteam/Grounding_LLMs_with_online_RL,v0.13.2/accelerate-0.13.2/examples/complete_cv_example.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/biasvariancelabs/aitlas,aitlas/models/mlp_mixer.py,timm.create_model;timm.create_model,timm/mixer_b16_224.goog_in21k_ft_in1k;timm/mixer_b16_224.goog_in21k_ft_in1k
github.com/microsoft/torchgeo,tests/models/test_resnet.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet50.a1_in1k
github.com/intel/e2eAIOK,e2eAIOK/ModelAdapter/backbone/factory.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet50.a1_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/vit_base_patch16_224_miil.in21k
github.com/lancopku/clip-openness,slip/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/Baiyuetribe/ncnn-models,image_classification/res2next50/models/convert.py,timm.create_model,timm/res2next50.in1k
github.com/HelixNGC7293/DeforumStableDiffusionLocal,deforum-stable-diffusion/src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/istiakshihab/automated-retail-checkout-aicity22,test/infer.py,timm.create_model,timm/vit_base_patch32_224.augreg_in21k_ft_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/SPNASNet_100_for_PyTorch/pthtar2onnx.py,timm.create_model,timm/spnasnet_100.rmsp_in1k
github.com/valentingol/gan-face-editing,pipeline/utils/depth_segmentation/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/shihyung/image_classification_flower102,src/flower102_train.py,timm.create_model,timm/tf_efficientnet_b0.ns_jft_in1k
github.com/seculayer/AutoAPE-challenge4,dacon/컴퓨터비전 이상치 탐지 알고리즘 경진대회/codes/model/model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b3.ra2_in1k;timm/wide_resnet50_2.racm_in1k;timm/wide_resnet101_2.tv_in1k;timm/cait_s36_384.fb_dist_in1k;timm/tf_efficientnet_b6.ns_jft_in1k
github.com/Reza-Zhu/SUES-200-Benchmark,model_.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k;timm/seresnet50.a1_in1k;timm/seresnet50.a1_in1k;timm/resnest50d.in1k;timm/resnest50d.in1k;timm/vgg16_bn.tv_in1k;timm/vgg16_bn.tv_in1k;timm/densenet201.tv_in1k;timm/densenet201.tv_in1k;timm/efficientnet_b4.ra2_in1k;timm/efficientnet_b4.ra2_in1k;timm/inception_v4.tf_in1k;timm/inception_v4.tf_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/seresnet50.a1_in1k
github.com/izmailovpavel/spurious_feature_learning,models/__init__.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/convnext_small.in12k_ft_in1k;timm/convnext_base.fb_in22k_ft_in1k;timm/convnext_large.fb_in22k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/beit_base_patch16_224.in22k_ft_in22k_in1k;timm/beit_large_patch16_224.in22k_ft_in22k_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/WangLibo1995/GeoSeg,geoseg/models/ABCNet.py,timm.create_model,timm/resnet18.a1_in1k
github.com/mukhal/grace,transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/rahimentezari/DataDistributionTransferLearning,src/models/simclr/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/dev/perf/Swin_Cifar10/vision-transformers-cifar10/train_cifar10.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/cxx226/DPF,model/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/Pseudo_label_learning/Task3/Task3_densenet121.py,timm.create_model;timm.create_model,timm/densenet121.ra_in1k;timm/densenet121.ra_in1k
github.com/deforum-art/sd-webui-deforum,scripts/deforum_helpers/src/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/gmlwns2000/sttabt,trainer/vit_approx_trainer.py,timm.create_model;timm.create_model,timm/deit_small_patch16_224.fb_in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/salesforce/UniControl,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Expedit-LargeScale-Vision-Transformer/Expedit-DPT,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Liuxinyv/SAZS,model/lseg_vit_zs.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Test/query/models_isc/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k
github.com/ThereforeGames/unprompted,lib_unprompted/stable_diffusion/controlnet/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Fannovel16/comfy_controlnet_preprocessors,v11/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/flyingsheepbin/pet-biometrics,v2_stage2/model_v2.py,timm.create_model,timm/tf_efficientnetv2_l.in21k_ft_in1k
github.com/yossigandelsman/rosetta_neurons,pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/thygate/stable-diffusion-webui-depthmap-script,dmidas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/ma3mool/goldeneye,src/util.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/huggingface/transformers,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/swin_double.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/dixiyao/Patch-Shuffling-Transformer,SpectralShuffling/model.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/sagizty/MAE,MAE_main.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/nianticlabs/simplerecon,modules/networks.py,timm.create_model,timm/mnasnet_100.rmsp_in1k
github.com/drinkingcoder/FlowFormer-Official,core/FlowFormer/encoders.py,timm.create_model;timm.create_model,timm/twins_svt_large.in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/FMInference/FlexGen,benchmark/third_party/transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/tlpss/keypoint-detection,keypoint_detection/models/backbones/maxvit_unet.py,timm.create_model;timm.create_model,timm/maxvit_nano_rw_256.sw_in1k
github.com/autonomousvision/stylegan-xl,feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/GenjiB/LAVISH,AVE/nets/ast_models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/deit_base_distilled_patch16_384.fb_in1k
github.com/aartykov/Latent-Composer-pytorch,annotators/midas/midas/backbones/beit.py,timm.create_model;timm.create_model;timm.create_model,timm/beit_large_patch16_512.in22k_ft_in22k_in1k;timm/beit_large_patch16_384.in22k_ft_in22k_in1k;timm/beit_base_patch16_384.in22k_ft_in22k_in1k
github.com/rossjillian/cog-controlnet-11,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/Sjyhne/MapAI-Competition,team_deepcrop/src/models/geoseg/models/ABCNet.py,timm.create_model,timm/resnet18.a1_in1k
github.com/deforum-art/deforum-stable-diffusion,src/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/SJTU-LIT/PEM_composition,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/lkk688/DeepDataMiningLearning,pytorch/torchhubmodel.py,timm.create_model;timm.create_model;timm.create_model,timm/mobilenetv3_large_100.ra_in1k;timm/resnet50.a1_in1k;timm/resnest26d.gluon_in1k
github.com/MCLAB-OCR/KnowledgeMiningWithSceneText,model/vit_knowbert_interaction_timm.py,timm.models.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/layumi/Person_reID_baseline_pytorch,model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swinv2_base_window8_256.ms_in1k;timm/convnext_base.fb_in22k_ft_in1k;timm/hrnet_w18.ms_aug_in1k
github.com/aurooj/WSG-VQA-VLTransformers,src/lxrt/vit_explore_code.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Heathcliff-saku/ViewFool_,classifier/predict_2.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/inception_v3.tv_in1k;timm/inception_resnet_v2.tf_in1k;timm/densenet121.ra_in1k;timm/efficientnet_b0.ra_in1k;timm/mixer_b16_224.goog_in21k_ft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/vgg16.tv_in1k;timm/mobilenetv2_120d.ra_in1k;timm/vgg19.tv_in1k;timm/densenet169.tv_in1k;timm/densenet201.tv_in1k;timm/inception_v4.tf_in1k;timm/resnet18.a1_in1k;timm/resnet34.a1_in1k;timm/resnet50.a1_in1k;timm/resnet101.a1h_in1k;timm/resnet152.a1h_in1k;timm/efficientnet_b1.ft_in1k;timm/efficientnet_b2.ra_in1k;timm/efficientnet_b3.ra2_in1k;timm/efficientnet_b4.ra2_in1k;timm/mobilenetv2_140.ra_in1k;timm/mixer_l16_224.goog_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/deit_base_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_tiny_patch16_224.fb_in1k;timm/swin_large_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/sgoldt/dist_inc_comp,dist_inc_comp.py,timm.create_model;timm.create_model,timm/densenet121.ra_in1k
github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,rijks_torch/learning_problems/vit.py,timm.create_model,timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k
github.com/JamesQFreeman/LoRA-ViT,train_timm.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Confusezius/Characterizing_Generalization_in_DeepMetricLearning,architectures/efficientb0.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/Sierkinhane/VisorGPT,demo/ControlNet/controlnet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/salesforce/UniControl,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zhenxingjian/Partial_Distance_Correlation,Partial_Distance_Correlation/ViT_model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_r50_s32_224.augreg_in21k_ft_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/demo.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/xijiu9/Train_Transformers_with_INT4,SingleDivide/transformersLocal/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/eps696/SDfu,src/xtra/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/tadeephuy/TedSeg,models/backbone.py,timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/tf_efficientnet_b7.ns_jft_in1k
github.com/juansensio/blog,072_pytorch_docker/ddp.py,timm.create_model,timm/tf_efficientnet_b5.ns_jft_in1k
github.com/Perp-Neg/Perp-Neg-stablediffusion,stable-dreamfusion/dpt.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/dodler/kgl,lyft_motion_prediction/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnest200e.in1k;timm/resnest101e.in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Test/models/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/ThereforeGames/unprompted,lib_unprompted/stable_diffusion/clipseg/models/vitseg.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/OPEN-AIR-SUN/Cerberus,model/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/facebookresearch/home-robot,src/home_robot/home_robot/perception/detection/lseg/modules/models/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/MengLiuPurdue/Graph-Topological-Data-Analysis,train_analyze_imagenet_1k.py,timm.create_model,timm/volo_d5_224.sail_in1k
github.com/MehmetAygun/demistfy_correspondence,backbone/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Test/query/models_isc/hrnet.py,timm.create_model,timm/hrnet_w30.ms_in1k
github.com/i-Eval/ieval-instruction,src/transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/kyegomez/Finetuning-Suite,Imagebind/Point-Bind/models/PointBind_models.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/BaratiLab/ManufacturingNet,ManufacturingNet/models/vit.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Picsart-AI-Research/Text2Video-Zero,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/vit_base_patch32_224/vit_train.py,timm.models.create_model;timm.create_model,timm/vit_base_patch32_224.augreg_in21k_ft_in1k
github.com/elias-ramzi/ROADMAP,roadmap/models/net.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_small_distilled_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k;timm/deit_base_distilled_patch16_224.fb_in1k;timm/deit_base_distilled_patch16_224.fb_in1k;timm/deit_base_patch16_384.fb_in1k;timm/deit_base_distilled_patch16_384.fb_in1k;timm/deit_base_distilled_patch16_384.fb_in1k
github.com/salesforce/ULIP,models/ULIP_models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/feizc/Video-Stable-Diffusion,deforum-stable-diffusion/src/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Stability-AI/stablediffusion,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/JinjingZhu/PMTrans,models/swin_pm.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k
github.com/VQAssessment/BVQI,pyiqa/archs/iqt_arch.py,timm.create_model,timm/inception_resnet_v2.tf_in1k
github.com/jiyeoon/TIL,etc/ArcFace/model.py,timm.create_model,timm/eca_nfnet_l0.ra2_in1k
github.com/isl-org/MiDaS,midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/gyhandy/Humanoid-Vision-Engine,preprocess_dataset/3_compute_feature_images/preprocessed_shape/DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/KU-CVLAB/3DFuse,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/HabanaAI/Model-References,PyTorch/generative_models/stable-diffusion-v-2-1/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/lishiqianhugh/LfID,LfI/train.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/beit_base_patch16_224.in22k_ft_in22k_in1k
github.com/enryu43/anifusion-stable-diffusion2,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/YuxinWenRick/canary-in-a-coalmine,models/utils.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Zeju1997/oft,oft-control/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Ascend/samples,best_practices/contrib/RT-GazeEstimation/Client/pth2onnx.py,timm.create_model,timm/resnet18.a1_in1k
github.com/IDEA-Research/HumanSD,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/juansensio/blog,071_pytorch_lightning_optim/kk.py,timm.create_model,timm/tf_efficientnet_b5.ns_jft_in1k
github.com/pfnet-research/distilled-feature-fields,encoders/lseg_encoder/modules/models/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/beroguedou/basmatinet,basmatinet/app/models.py,timm.create_model,timm/efficientnet_b4.ra2_in1k
github.com/yujiariyasu/siim_covid19_detection,ian-siim/detect/skp/models/backbones.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/mixnet_s.ft_in1k;timm/resnet18d.ra2_in1k;timm/resnest14d.gluon_in1k;timm/nfnet_l0.ra2_in1k
github.com/abhrac/xmodal-vit,src/networks/photo_encoder_student.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/EPFL-VILAB/3DCommonCorruptions,train/models/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Test/query/models_isc/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k
github.com/Georgefwt/Face-Landmark-ControlNet,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_vit.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/validate.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/microsoft/LMOps,minillm/transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/alex-moon/vc,vc/service/helper/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/kspruthviraj/Plankiformer,utils/for_cifar100.py,timm.create_model;timm.create_model,timm/tf_efficientnet_b7.ns_jft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k
github.com/mhh0318/Cocktail,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/haotian-liu/transformers_llava,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/rossjillian/cog-controlnet-11,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/ygtxr1997/ReliableSwap,modules/third_party/simswap/pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/bryanyu1997/Data-Efficient-3D-Learner,tools/DPT/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sun-umn/Transfer-Learning-in-Medical-Imaging,utils/models.py,timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/ken2576/vision-nerf,network/vit.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/GeorgeCazenavette/glad,stylegan_xl/feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Qualcomm-AI-research/oscillations-qat,models/efficientnet_lite_quantized.py,timm.models.create_model;timm.models.create_model,timm/efficientnet_lite0.ra_in1k
github.com/regob/vehicle_reid,model.py,timm.create_model;timm.create_model;timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/hrnet_w18.ms_aug_in1k;timm/nasnetalarge.tf_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/Inference/inference_task3.py,timm.create_model;timm.create_model,timm/densenet121.ra_in1k;timm/efficientnet_b3.ra2_in1k
github.com/DachengLi1/MPCFormer,transformers/examples/pytorch/vision-transformers-cifar10/train_cifar10.py,timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/chanlilong/4D_NET_pytorch,detector_models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/resnet50.a1_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/Ascend/ModelZoo-PyTorch,ACL_PyTorch/contrib/cv/classfication/pnasnet5large/pnasnet5large_onnx.py,timm.create_model,timm/pnasnet5large.tf_in1k
github.com/AlonzoLeeeooo/LCDG,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/csp_resnext50-mish/demo.py,timm.models.create_model,timm/cspresnext50.ra_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task1/V-Net/Classifier_label3.py,timm.create_model,timm/resnet101.a1h_in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/db0/nataili,ldm2/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/csp_resnext50-mish/pthtar2onx.py,timm.models.create_model,timm/cspresnext50.ra_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/swin.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/wang22ti/OpenAUC,utils/model_utils.py,timm.create_model;timm.create_model,timm/resnet50.a1_in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,rijks_torch/learning_problems/beit.py,timm.create_model,timm/beit_base_patch16_224.in22k_ft_in22k_in1k
github.com/ZitongYu/Flex-Modal-FAS,models/ViT_Base_CA.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/gudovskiy/cflow-ad,model.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/kssteven418/BigLittleDecoder,src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/tadeephuy/CoFo,models/backbone.py,timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/tf_efficientnet_b7.ns_jft_in1k
github.com/microsoft/DeepSpeedExamples,training/data_efficiency/vit_finetuning/models/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sagizty/Insight,StarUp/model/ViT.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/610265158/Peppa_Pig_Face_Landmark,TRAIN/face_landmark/lib/core/model/face_model.py,timm.create_model,timm/tf_mobilenetv3_large_minimal_100.in1k
github.com/VMarsocci/3DCD,models/SUNet18.py,timm.create_model,timm/resnet18.a1_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/pthtar2onx.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/sayakpaul/robustness-vit,imagenet_results/imagenet_p/test.py,timm.create_model;timm.create_model,timm/vit_large_patch16_224.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task2_vgg19/fold3.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/lufficc/SC-Transformer,modeling/e2e_model_ban_v4_query.py,timm.create_model;timm.create_model;timm.create_model,timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k
github.com/Mikubill/sd-webui-controlnet,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/drivendataorg/cloud-cover-winners,1st place/Example_submission/effnetv2b2_unet_eff1_ensemble/cloud_model.py,timm.create_model,timm/tf_efficientnetv2_b2.in1k
github.com/abhishekkrthakur/tez,examples/image/flower_classification.py,timm.create_model,timm/resnet18.a1_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/brycedrennan/imaginAIry,imaginairy/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yylime/FlyAI_ImgCls,MushroomsRecognition/net.py,timm.create_model;timm.create_model,timm/cait_s24_384.fb_dist_in1k
github.com/yaoching0/Traditional-Chinese-Street-View-Text-Recognition,data/generate_feature_for_model_Ensemble_model.py,timm.create_model;timm.create_model;timm.create_model,timm/eca_nfnet_l2.ra3_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/loretoparisi/hf-experiments,src/projected_gan/projected_gan/pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/abhrac/xmodal-vit,src/networks/sketch_encoder_student.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/alibaba/easyrobust,examples/ood_detection/BATS/test_ood.py,timm.models.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/w8988998ww/https-github.com-Mikubill-sd-webui-controlnet,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Confusezius/Characterizing_Generalization_in_DeepMetricLearning,architectures/multifeature_efficientb0.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/yhlleo/MJP,gradvit/gradvit_eval_grad-only.py,timm.create_model;timm.create_model.cuda,timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/boostcampaitech2/final-project-level3-cv-04,model_lab/frame_classification/custom/full/recipe.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/zfkuang/PaletteNeRF,third-party/lang-seg/modules/models/lseg_vit_zs.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/layumi/3D-Magic-Mirror,network/model_res.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet34d.ra2_in1k;timm/hrnet_w18.ms_aug_in1k;timm/hrnet_w18.ms_aug_in1k;timm/hrnet_w18_small_v2.ms_in1k;timm/hrnet_w18_small.ms_in1k
github.com/budnikm/aml,lib/networks/imageretrievalnet.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/tf_efficientnet_b3.ns_jft_in1k
github.com/ashawkey/torch-merf,depth_tools/dpt.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/SHEERANER/Modelzoo_centermask_pytorch,ACL_PyTorch/contrib/cv/classfication/TResNet/TResNet_pth2onnx.py,timm.create_model,timm/tresnet_m.miil_in21k_ft_in1k
github.com/lunarring/latentblending,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/rossjillian/cog-controlnet-11,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/hwk0702/keras2torch,Adversarial_Attack/Fast_Gradient_Sign_Method/main.py,timm.create_model,timm/resnet50.a1_in1k
github.com/tien-d/EgoDepthNormal,networks/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yujiariyasu/siim_covid19_detection,ian-siim/classify/skp/models/backbones.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnet_b0.ra_in1k;timm/mixnet_s.ft_in1k;timm/resnet18d.ra2_in1k;timm/resnest14d.gluon_in1k;timm/nfnet_l0.ra2_in1k
github.com/WJ-Chang-42/ASTransformer,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/mtailanian/uflow,src/feature_extraction.py,timm.create_model;timm.create_model;timm.create_model,timm/cait_m48_448.fb_dist_in1k;timm/cait_s24_224.fb_dist_in1k
github.com/Zhendong-Wang/Prompt-Diffusion,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/valentyn1boreiko/SVCEs_code,utils/models/model_factory_224.py,timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model,timm/resnet50.a1_in1k;timm/tresnet_m.miil_in21k_ft_in1k;timm/seresnext26t_32x4d.bt_in1k;timm/seresnext50_32x4d.racm_in1k
github.com/rossjillian/cog-controlnet-11,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/aofrancani/DPT-VO,dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Ascend/ModelZoo-PyTorch,PyTorch/contrib/cv/classification/MobileNetV3_large_100_for_PyTorch/validate.py,timm.models.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/zhoudw-zdw/RevisitingCIL,convs/vision_transformer_adapter.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/XiandaGuo/OpenStereo,openstereo/modeling/models/igevstereo/extractor.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/gangweiX/Fast-ACVNet,models/Fast_ACV_plus.py,timm.create_model,timm/mobilenetv2_100.ra_in1k
github.com/wxjiao/ParroT,transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/bytedance/DiffusionEngine,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ehuynh1106/TinyImageNet-Transformers,main.py,timm.models.create_model;timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/cait_s36_384.fb_dist_in1k;timm/deit_base_distilled_patch16_384.fb_in1k;timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/Inference/inference_task2.py,timm.create_model,timm/vgg19.tv_in1k
github.com/WangWenhao0716/VSC-MatchingTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/vit_double.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/boostcampaitech4lv23cv2/final-project-level3-cv-13,ml/pipeline/model.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet50.a1_in1k;timm/efficientnet_b0.ra_in1k;timm/efficientnet_b4.ra2_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k
github.com/pollinations/lucid-sonic-dreams-xl,stylegan_xl/feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/EPFL-VILAB/omnidata,omnidata_tools/torch/modules/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/ZhangYuanhan-AI/OmniBenchmark,linear_probe/models/timm_effnet.py,timm.create_model,timm/efficientnet_b4.ra2_in1k
github.com/IndoorAdventurer/ViTTransferLearningForArtClassification,rijks_torch/learning_problems/deit.py,timm.create_model;timm.create_model,timm/deit_base_patch16_224.fb_in1k;timm/deit_tiny_patch16_224.fb_in1k
github.com/IIT-PAVIS/Positional_Diffusion,puzzle_diff/model/backbones/backbone_vist.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/zyddnys/manga-image-translator,manga_translator/inpainting/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/NVlabs/prismer,experts/depth/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/levit.py,timm.create_model,timm/levit_384.fb_dist_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/Pseudo_label_learning/Task3/Task3_efficientnet_b3.py,timm.create_model;timm.create_model,timm/efficientnet_b3.ra2_in1k;timm/efficientnet_b3.ra2_in1k
github.com/XmYx/ainodes-engine,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/kaleido-lab/dolphin,modules/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/theNded/mini-omnidata,midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/wolverinn/stable-diffusion-multi-user,repositories/stable-diffusion-stability-ai/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Baiyuetribe/ncnn-models,image_classification/mobilenet_v3/models/convert.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/facebookresearch/comet_memory_dialog,models/gpt2_mm/utils/extract_memory_features.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/zhenxingjian/Partial_Distance_Correlation,Partial_Distance_Correlation/densenet.py,timm.create_model,timm/densenet121.ra_in1k
github.com/hbchen121/AICITY2022_Track2_SSM,models/resnest.py,timm.create_model,timm/resnest50d.in1k
github.com/yilundu/cross_attention_renderer,midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/thu-ml/controlvideo,annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/sagizty/Multi-Stage-Hybrid-Transformer,Hybrid/getmodel.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_224.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_384.augreg_in21k_ft_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_tiny_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vgg16_bn.tv_in1k;timm/vgg16.tv_in1k;timm/vgg19_bn.tv_in1k;timm/vgg19.tv_in1k;timm/deit_base_patch16_384.fb_in1k;timm/deit_base_patch16_224.fb_in1k;timm/twins_pcpvt_base.in1k;timm/pit_b_224.in1k;timm/convit_base.fb_in1k;timm/botnet26t_256.c1_in1k;timm/densenet121.ra_in1k;timm/pvt_v2_b0.in1k;timm/visformer_small.in1k;timm/coat_mini.in1k;timm/swin_base_patch4_window12_384.ms_in22k_ft_in1k;timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k;timm/mobilenetv3_large_100.ra_in1k;timm/mobilevit_s.cvnets_in1k;timm/inception_v3.tv_in1k;timm/crossvit_base_240.in1k;timm/coat_lite_small.in1k
github.com/huggingface/accelerate,examples/cv_example.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/inspire-group/PatchCleanser,utils/setup.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Test/models/vit.py,timm.models.create_model;timm.models.create_model;timm.models.create_model,timm/deit_tiny_patch16_224.fb_in1k;timm/deit_small_patch16_224.fb_in1k;timm/deit_base_patch16_224.fb_in1k
github.com/Picsart-AI-Research/PAIR-Diffusion,ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/zfkuang/PaletteNeRF,third-party/lang-seg/modules/models/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/robintzeng/mask-rcnn-Pytorch,model/modified_faster_rcnn.py,timm.create_model,timm/cspresnet50.ra_in1k
github.com/CristianoPatricio/coherent-cbe-skin,modules/model_builder.py,timm.create_model;timm.create_model,timm/seresnext26d_32x4d.bt_in1k;timm/seresnext26d_32x4d.bt_in1k
github.com/xiaoxiaokuaile/2022_ZTE_Img_Denoising,初赛总结/code/model/ResNet18_Unet2.py,timm.create_model,timm/resnet18.a1_in1k
github.com/Li-Wanhua/Label2Label,Face_Attribute/model.py,timm.models.create_model;timm.models.create_model,timm/resnet50.a1_in1k
github.com/thygate/stable-diffusion-webui-depthmap-script,dmidas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/devch1013/YAICON-Ditto,ditto/ai_models/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/memmelma/VO-Transformer,pointnav_vo/depth_estimator/modules/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/scott-yjyang/DiffMIC,model.py,timm.models.create_model,timm/pvt_v2_b2.in1k
github.com/yaoching0/Traditional-Chinese-Street-View-Text-Recognition,inference.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/eca_nfnet_l2.ra3_in1k
github.com/pfnet-research/distilled-feature-fields,encoders/lseg_encoder/modules/models/lseg_vit_zs.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/flowersteam/Grounding_LLMs_with_online_RL,v0.13.2/accelerate-0.13.2/examples/cv_example.py,timm.create_model,timm/resnet50d.ra2_in1k
github.com/juansensio/blog,071_pytorch_lightning_optim/ddp.py,timm.create_model,timm/tf_efficientnet_b5.ns_jft_in1k
github.com/610265158/face_landmark_pytorch,lib/core/base_trainer/model.py,timm.create_model;timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/krrish94/lseg-minimal,lseg/lseg_vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch32_384.augreg_in21k_ft_in1k
github.com/nicolasugrinovic/size_depth_disambiguation,external/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/adambielski/move-seg,discriminators/pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/patrickvonplaten/controlnet_aux,src/controlnet_aux/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/megvii-research/RealFlow,DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task2_vgg19/fold1.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/asromahin/fline,examples/fakes/fake_photo_classifier.py,timm.create_model,timm/densenet121.ra_in1k
github.com/boostcampaitech3/level1-image-classification-level1-recsys-07,code/model/model.py,timm.create_model;timm.create_model,timm/efficientnetv2_rw_t.ra2_in1k
github.com/moothes/SALOD,methods/menet.py,timm.create_model,timm/resnet50.a1_in1k
github.com/annahedstroem/MetaQuantus,scripts/run_benchmarking.py,timm.create_model,timm/deit_tiny_distilled_patch16_224.fb_in1k
github.com/yeates/MaGIC,annotator/depth/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/JonasGeiping/breaching,breaching/cases/models/model_preparation.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/runpod/serverless-workers,workers/ControlNet/annotator/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/yuniw18/Joint_360depth,evaluate/DPT/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task2_vgg19/fold2.py,timm.create_model;timm.create_model,timm/vgg19.tv_in1k;timm/vgg19.tv_in1k
github.com/edornd/contrastive-distillation,scripts/test_amp.py,timm.create_model,timm/tresnet_l.miil_in1k
github.com/adodge/ComfyLib,comfy/hazard/ldm/modules/midas/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/thygate/stable-diffusion-webui-depthmap-script,dmidas/backbones/swin2.py,timm.create_model;timm.create_model;timm.create_model,timm/swinv2_tiny_window16_256.ms_in1k
github.com/mbaradad/depth_prompt,dpt/dpt/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/Mostafa-EHD/Diabetic_Retinopathy_OCTA,Task2&3/5-fold_cross-validation_training/Task3_efficientnet_b2/fold2.py,timm.create_model;timm.create_model,timm/efficientnet_b2.ra_in1k;timm/efficientnet_b2.ra_in1k
github.com/HolyWu/vs-midas,vsmidas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/yossigandelsman/rosetta_neurons,feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/MotasemAlfarra/Online_Test_Time_Adaptation,models/resnets.py,timm.create_model,timm/resnet50_gn.a1h_in1k
github.com/ML-GSAI/Revisiting-Dis-vs-Gen-Classifiers,main_extract_features.py,timm.create_model,timm/vit_base_patch16_224.augreg_in21k
github.com/canktech/xview2unet,efflocunet.py,timm.create_model,timm/efficientnet_b0.ra_in1k
github.com/businiaoo/PRCV2021-Change-Detection-Contest-2nd-place-Solution,code/models/backbone/efficientnetv2_timm.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/efficientnetv2_rw_s.ra2_in1k;timm/efficientnetv2_rw_m.agc_in1k
github.com/ffs333/2nd_place_GISLR,GISLR_utils/keras_models/transfer.py,timm.create_model,timm/rexnet_100.nav_in1k
github.com/Zhendong-Wang/Diffusion-GAN,diffusion-projected-gan/pg_modules/projector.py,timm.create_model,timm/tf_efficientnet_lite0.in1k
github.com/layer6ai-labs/tr0n,tr0n/modules/sgxl_utils/feature_networks/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/k-zha14/Zoom-VQA,IQA/models/CPNetMulti.py,timm.create_model,timm/convnext_tiny.in12k_ft_in1k
github.com/VietHoang1512/CVPR-track-5,src/experiments/cvpr_duo_vision_transformer.py,timm.create_model;timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k;timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/jaylenwang7/DNN-Dataflow-Resilience,helpers.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/thu-ml/ares,pytorch_ares/test/test_black_box_attack.py,timm.create_model,timm/resnet50.a1_in1k
github.com/FMInference/H2O,h2o_flexgen/benchmark/third_party/transformers/src/transformers/models/levit/convert_levit_timm_to_pytorch.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/levit_128s.fb_dist_in1k;timm/levit_128.fb_dist_in1k;timm/levit_192.fb_dist_in1k;timm/levit_256.fb_dist_in1k;timm/levit_384.fb_dist_in1k
github.com/isLinXu/TrainNetHub,YOLO/yolov5_master/kindle/generator/pretrained.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/lllyasviel/ControlNet-v1-1-nightly,annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/swin.py,timm.create_model,timm/swin_large_patch4_window12_384.ms_in22k_ft_in1k
github.com/dixiyao/Patch-Shuffling-Transformer,AdaptiveAttacker/model.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/NICE-FUTURE/predict-gender-and-age-from-camera,models.py,timm.create_model,timm/resnet50.a1_in1k
github.com/abhishekkrthakur/tez,examples/image/dogs_vs_cats.py,timm.create_model,timm/resnet18.a1_in1k
github.com/bamps53/kaggle-autonomous-driving2019,models/centernet.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/tf_efficientnet_b7.ns_jft_in1k
github.com/ShuzhaoXie/Armol,src/armor_train.py,timm.create_model,timm/mobilenetv3_large_100.ra_in1k
github.com/WangWenhao0716/VSC-DescriptorTrack-Submission,Training/Stage_23/dg/models_gem_waveblock_balance_cos/swin_double.py,timm.create_model,timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k
github.com/dodler/kgl,cassava/pazzle_mix/model_pazzle_mix.py,timm.create_model,timm/seresnext50_32x4d.racm_in1k
github.com/anvie/stable-headshot,extensions/sd-webui-controlnet/annotator/zoe/zoedepth/models/base_models/midas_repo/midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/isl-org/MiDaS,midas/backbones/vit.py,timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/valentyn1boreiko/DVCEs,utils_svces/models/model_factory_224.py,timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model;timm.models.factory.create_model,timm/resnet50.a1_in1k;timm/tresnet_m.miil_in21k_ft_in1k;timm/seresnext26t_32x4d.bt_in1k;timm/seresnext50_32x4d.racm_in1k
github.com/jhong93/spot,train_e2e.py,timm.create_model;timm.create_model,timm/convnext_tiny.in12k_ft_in1k
github.com/dogoulis/kg_visual_skin_cancer,cv/train.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/resnet18.a1_in1k;timm/resnet50.a1_in1k;timm/swin_tiny_patch4_window7_224.ms_in1k;timm/swin_small_patch4_window7_224.ms_in22k_ft_in1k;timm/vit_tiny_patch16_224.augreg_in21k_ft_in1k;timm/vit_small_patch16_224.augreg_in21k_ft_in1k
github.com/usc-sail/mica-MovieCLIP,feature_extraction/extract_vit_features.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/KevinMathewT/Cassava-Disease-Detection-Kaggle,src/models/models.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/CatoGit/Comparing-the-Performance-of-Deepfake-Detection-Methods-on-Benchmark-Datasets,deepfake_detector/pretrained_mods/efficientnetb1lstm.py,timm.create_model,timm/efficientnet_b1.ft_in1k
github.com/kspruthviraj/Plankiformer,utils/for_inaturalist.py,timm.create_model;timm.create_model,timm/tf_efficientnet_b7.ns_jft_in1k;timm/deit_base_distilled_patch16_224.fb_in1k
github.com/Healthcare-Robotics/visual-force-torque,prediction/model_vit.py,timm.create_model,timm/vit_base_patch16_224.augreg2_in21k_ft_in1k
github.com/Borda/kaggle_image-classify,tests/imet_collect/test_models.py,timm.create_model;timm.create_model,timm/resnet18.a1_in1k
github.com/yaochih/GCVD-release,models/depth/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
github.com/YongzhouPan/Mono-Navigation,2_monocular_depth_ROS/midas_ws/MiDaS/midas/vit.py,timm.create_model;timm.create_model;timm.create_model;timm.create_model;timm.create_model,timm/vit_large_patch16_384.augreg_in21k_ft_in1k;timm/vit_base_patch16_384.augreg_in21k_ft_in1k
